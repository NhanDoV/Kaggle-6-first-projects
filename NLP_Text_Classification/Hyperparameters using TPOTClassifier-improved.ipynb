{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(r\"train.csv\", usecols = [\"text\", \"target\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['col_names : \\ttext', 'col_names : \\ttarget'], dtype='object')\n",
      "\n",
      "\n",
      "Data-dimensions: \t(7613, 2)\n",
      "\n",
      "\n",
      "Count the not-null values of each features: \n",
      "text      7613\n",
      "target    7613\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"col_names : \\t\" + df.columns)\n",
    "print('\\n')\n",
    "print(\"Data-dimensions: \\t\" + str(df.shape))\n",
    "print('\\n')\n",
    "print(\"Count the not-null values of each features: \\n\" + str(df.notnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new dimension after checking duplicate & removing is:\t(7521, 2)\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "print(\"The new dimension after checking duplicate & removing is:\\t\" + str(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>Text_length</th>\n",
       "      <th>Numb_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  Text_length  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1           69   \n",
       "1             Forest fire near La Ronge Sask. Canada       1           38   \n",
       "2  All residents asked to 'shelter in place' are ...       1          133   \n",
       "3  13,000 people receive #wildfires evacuation or...       1           65   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1           88   \n",
       "\n",
       "   Numb_words  \n",
       "0          13  \n",
       "1           7  \n",
       "2          22  \n",
       "3           8  \n",
       "4          16  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text_length'] = df['text'].str.len()\n",
    "df['Numb_words'] = df['text'].str.split().map(lambda x: len(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from spellchecker import SpellChecker    \n",
    "\n",
    "def process_text(str_input):\n",
    "    ## 1. Remove url_link\n",
    "    remove_url = re.compile(r'https?://\\S+|www\\.\\S+').sub(r'', str_input)\n",
    "    \n",
    "    ## 2. Remove html_link\n",
    "    remove_html = re.compile(r'<.*?>').sub(r'', remove_url)\n",
    "    \n",
    "    ## 3. Remove Emojis\n",
    "    remove_emo = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE).sub(r'', remove_html)\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", remove_emo).lower().split()    \n",
    "        \n",
    "    ## 4. spell_correction\n",
    "    # spell = SpellChecker()\n",
    "    # words = [spell.correction(word) for word in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text_process = CountVectorizer(analyzer = process_text).fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target.to_numpy()\n",
    "X = df[['text', 'Text_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=310.0, style=ProgressStyle(deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 2 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 3 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 4 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 5 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 6 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 7 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 8 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 9 - Current best internal CV score: 0.7690016574046992\n",
      "Generation 10 - Current best internal CV score: 0.7845765674029299\n",
      "Generation 11 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 12 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 13 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 14 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 15 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 16 - Current best internal CV score: 0.7870469670216186\n",
      "Generation 17 - Current best internal CV score: 0.7927460559906695\n",
      "Generation 18 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 19 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 20 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 21 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 22 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 23 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 24 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 25 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 26 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 27 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 28 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 29 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 30 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 31 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 32 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 33 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 34 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 35 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 36 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 37 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 38 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 39 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 40 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 41 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 42 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 43 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 44 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 45 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 46 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 47 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 48 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 49 - Current best internal CV score: 0.8026233213812428\n",
      "Generation 50 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 51 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 52 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 53 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 54 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 55 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 56 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 57 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 58 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 59 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 60 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 61 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 62 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 63 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 64 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 65 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 66 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 67 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 68 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 69 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 70 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 71 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 72 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 73 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 74 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 75 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 76 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 77 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 78 - Current best internal CV score: 0.8026235019264168\n",
      "Generation 79 - Current best internal CV score: 0.8026238630167655\n",
      "Generation 80 - Current best internal CV score: 0.8026238630167655\n",
      "Generation 81 - Current best internal CV score: 0.8026238630167655\n",
      "Generation 82 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 83 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 84 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 85 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 86 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 87 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 88 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 89 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 90 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 91 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 92 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 93 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 94 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 95 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 96 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 97 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 98 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 99 - Current best internal CV score: 0.8033843192905297\n",
      "Generation 100 - Current best internal CV score: 0.8033843192905297\n",
      "\n",
      "Best pipeline: BernoulliNB(SelectPercentile(input_matrix, percentile=97), alpha=1.0, fit_prior=False)\n",
      "0.7948604342046965\n",
      "Fit&trainning time :  32114.64671087265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "## Set test_size = 0.3\n",
    "test_size = 0.3\n",
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify = y, random_state = 42)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer = process_text)\n",
    "\n",
    "tfidf_train = tfidf_vect.fit(X_train['text']).transform(X_train['text']) \n",
    "tfidf_test = tfidf_vect.fit(X_train['text']).transform(X_test['text'])\n",
    "\n",
    "X_train_vect = pd.concat([\n",
    "                            X_train[['Text_length']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_train.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "X_test_vect = pd.concat([\n",
    "                            X_test[['Text_length']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_test.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "tpot_clf = TPOTClassifier(generations=100, population_size=10, offspring_size=3 , cv=5,\n",
    "                          verbosity=2, random_state=42)\n",
    "\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "tpot_clf.fit(X_train_vect, y_train)\n",
    "\n",
    "# Score on the test set\n",
    "print(tpot_clf.score(X_test_vect, y_test))\n",
    "print ('Fit&trainning time : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hence, the best method is using the Pipeline belong with BernoulliNB and SelectPercentile.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 1.**`First, we only focus on the BernoulliNB (without using Pipeline)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BernoulliNB(fit_prior=False)\n",
    "clf.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test_vect)\n",
    "\n",
    "train_acc_NVB = accuracy_score(y_train, clf.predict(X_train_vect)) * 100.0\n",
    "\n",
    "test_acc_NVB = accuracy_score(y_test, preds) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the confusion_matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Accuracy: 90.67%\n",
      "Testing_Accuracy: 80.91%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.84      1303\n",
      "           1       0.83      0.69      0.76       981\n",
      "\n",
      "    accuracy                           0.81      2284\n",
      "   macro avg       0.81      0.79      0.80      2284\n",
      "weighted avg       0.81      0.81      0.81      2284\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1167  136]\n",
      " [ 300  681]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_NVB)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_NVB)\n",
    "print(classification_report(y_test, preds))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using F-measure in the `confusion matrix`**\n",
    "\n",
    "Remind that, `A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix. The confusion matrix shows the ways in which your classification model is confused when it makes predictions. It gives us insight not only into the errors being made by a classifier but more importantly the types of errors that are being made.`\n",
    "\n",
    "$$\\begin{array}{ccc} & \\text{Class 1_predicted} & \\text{Class 2_predicted} \\\\ \\text{Class 1_actual} & \\text{TP} & \\text{FN} \\\\ \\text{Class 2_actual} & \\text{TN} & \\text{FP} \\end{array}$$\n",
    "\n",
    "where,\n",
    "\n",
    "-1) `True Positive (TP)` : Observation is positive, and is predicted to be positive.\n",
    "\n",
    "-2) `False Negative (FN)` : Observation is positive, but is predicted negative.\n",
    "\n",
    "-3) `True Negative (TN)` : Observation is negative, and is predicted to be negative.\n",
    "\n",
    "-4) `False Positive (FP)` : Observation is negative, but is predicted positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1167, 300, 136)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mat = confusion_matrix(y_test, preds)\n",
    "TP = Mat[0, 0]    ## \n",
    "FP = Mat[1, 0]\n",
    "FN = Mat[0, 1]\n",
    "TP, FP, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the value of `Recall` & `Precision` from the `confusion_matrix`**, \n",
    "\n",
    "We have\n",
    "$$ F_{\\text{score}} = \\dfrac{2*\\text{recall}*\\text{precision} }{\\text{recall}+\\text{precision}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure = 84.26%.\n"
     ]
    }
   ],
   "source": [
    "Reca = TP/(TP + FN)\n",
    "Pres = TP/(TP + FP)\n",
    "F_scr = 2*Reca*Pres/(Reca + Pres)*100\n",
    "print(\"F-measure = %.2f%%.\"% F_scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach 2. Now, I try to add one more feature: `Number of words` to this model. Let see the F_measure in the confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Accuracy: 90.67%\n",
      "Testing_Accuracy: 80.91%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.84      1303\n",
      "           1       0.83      0.69      0.76       981\n",
      "\n",
      "    accuracy                           0.81      2284\n",
      "   macro avg       0.81      0.79      0.80      2284\n",
      "weighted avg       0.81      0.81      0.81      2284\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1167  136]\n",
      " [ 300  681]]\n",
      "F-measure = 84.26%.\n"
     ]
    }
   ],
   "source": [
    "y = df.target.to_numpy()\n",
    "X = df[['text', 'Text_length', 'Numb_words']]\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "## Set test_size = 0.3\n",
    "test_size = 0.3\n",
    "start = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify = y, random_state = 42)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer = process_text)\n",
    "\n",
    "tfidf_train = tfidf_vect.fit(X_train['text']).transform(X_train['text']) \n",
    "tfidf_test = tfidf_vect.fit(X_train['text']).transform(X_test['text'])\n",
    "\n",
    "X_train_vect = pd.concat([\n",
    "                            X_train[['Text_length', 'Numb_words']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_train.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "X_test_vect = pd.concat([\n",
    "                            X_test[['Text_length', 'Numb_words']].reset_index(drop = True), \n",
    "                            pd.DataFrame(tfidf_test.toarray())\n",
    "                        ], axis = 1)\n",
    "\n",
    "clf = BernoulliNB(alpha = 1.0, fit_prior=False)\n",
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "preds = clf.predict(X_test_vect)\n",
    "\n",
    "train_acc_NVB = accuracy_score(y_train, clf.predict(X_train_vect)) * 100.0\n",
    "\n",
    "test_acc_NVB = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_NVB)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_NVB)\n",
    "print(classification_report(y_test, preds))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, preds))\n",
    "\n",
    "Mat = confusion_matrix(y_test, preds)\n",
    "TP = Mat[0, 0]\n",
    "FP = Mat[1, 0]\n",
    "FN = Mat[0, 1]\n",
    "\n",
    "Reca = TP/(TP + FN)\n",
    "Pres = TP/(TP + FP)\n",
    "F_scr = 2*Reca*Pres/(Reca + Pres)*100\n",
    "print(\"F-measure = %.2f%%.\"% F_scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the `F_measure = 84.26` and there are nothing change!!\n",
    "\n",
    "**Approach 3. Finally, we use the Pipeline and BernoulliBN and SelectPercentile.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scl',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 BernoulliNB(alpha=SelectPercentile(percentile=97,\n",
       "                                                    score_func=<function f_classif at 0x00000273F50F4A68>),\n",
       "                             binarize=0.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf',  BernoulliNB(SelectPercentile(percentile = 97)))\n",
    "                   ])\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List the names in `pipeline` with `.named_steps`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scl': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'clf': BernoulliNB(alpha=SelectPercentile(percentile=97,\n",
       "                                    score_func=<function f_classif at 0x00000273F50F4A68>),\n",
       "             binarize=0.0, class_prior=None, fit_prior=True)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the statement in `clf`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=SelectPercentile(percentile=97,\n",
       "                                   score_func=<function f_classif at 0x00000273F50F4A68>),\n",
       "            binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.named_steps['clf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the params `alpha` and `fit_prior` into BernoulliNB()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.named_steps['clf'].set_params(alpha=1.0, fit_prior=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Verify the parameters in pipeline***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scl',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('clf',\n",
       "                 BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
       "                             fit_prior=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Accuracy: 90.50%\n",
      "Testing_Accuracy: 81.30%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84      1303\n",
      "           1       0.84      0.69      0.76       981\n",
      "\n",
      "    accuracy                           0.81      2284\n",
      "   macro avg       0.82      0.79      0.80      2284\n",
      "weighted avg       0.81      0.81      0.81      2284\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1172  131]\n",
      " [ 304  677]]\n",
      "F-measure = 84.35%.\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_vect, y_train)\n",
    "\n",
    "preds = clf.predict(X_test_vect)\n",
    "\n",
    "train_acc_NVB = accuracy_score(y_train, clf.predict(X_train_vect)) * 100.0\n",
    "\n",
    "test_acc_NVB = accuracy_score(y_test, preds) * 100.0\n",
    "\n",
    "print(\"Training_Accuracy: %.2f%%\" % train_acc_NVB)\n",
    "print(\"Testing_Accuracy: %.2f%%\" % test_acc_NVB)\n",
    "print(classification_report(y_test, preds))\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, preds))\n",
    "\n",
    "Mat = confusion_matrix(y_test, preds)\n",
    "TP = Mat[0, 0]\n",
    "FP = Mat[1, 0]\n",
    "FN = Mat[0, 1]\n",
    "\n",
    "Reca = TP/(TP + FN)\n",
    "Pres = TP/(TP + FP)\n",
    "F_scr = 2*Reca*Pres/(Reca + Pres)*100\n",
    "print(\"F-measure = %.2f%%.\"% F_scr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
